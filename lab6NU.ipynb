{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "006bea53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU\n",
      "В наборе предложений: 1,441\n",
      "\n",
      "Максимальная длина предложения:  1627\n",
      "Предложений длиннее 64 токена:  190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vanya\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Эпоха 1 из 4 \n",
      " Батч   10 из  324. Затраченное время: 00:00:29. Ошибка: 2.273017406463623.\n",
      " Батч   20 из  324. Затраченное время: 00:00:55. Ошибка: 0.5320193767547607.\n",
      " Батч   30 из  324. Затраченное время: 00:01:20. Ошибка: 0.6140555143356323.\n",
      " Батч   40 из  324. Затраченное время: 00:01:45. Ошибка: 0.6311876177787781.\n",
      " Батч   50 из  324. Затраченное время: 00:02:10. Ошибка: 0.5984649658203125.\n",
      " Батч   60 из  324. Затраченное время: 00:02:35. Ошибка: 0.7693603038787842.\n",
      " Батч   70 из  324. Затраченное время: 00:02:59. Ошибка: 0.8234623670578003.\n",
      " Батч   80 из  324. Затраченное время: 00:03:24. Ошибка: 1.0299198627471924.\n",
      " Батч   90 из  324. Затраченное время: 00:03:49. Ошибка: 0.7441975474357605.\n",
      " Батч  100 из  324. Затраченное время: 00:04:14. Ошибка: 0.6985324621200562.\n",
      " Батч  110 из  324. Затраченное время: 00:04:38. Ошибка: 0.6886499524116516.\n",
      " Батч  120 из  324. Затраченное время: 00:05:02. Ошибка: 0.2578735053539276.\n",
      " Батч  130 из  324. Затраченное время: 00:05:27. Ошибка: 0.6282992362976074.\n",
      " Батч  140 из  324. Затраченное время: 00:05:52. Ошибка: 0.6216738820075989.\n",
      " Батч  150 из  324. Затраченное время: 00:06:17. Ошибка: 0.2955881655216217.\n",
      " Батч  160 из  324. Затраченное время: 00:06:42. Ошибка: 0.5972463488578796.\n",
      " Батч  170 из  324. Затраченное время: 00:07:06. Ошибка: 0.625449538230896.\n",
      " Батч  180 из  324. Затраченное время: 00:07:31. Ошибка: 0.37089502811431885.\n",
      " Батч  190 из  324. Затраченное время: 00:07:56. Ошибка: 0.7383761405944824.\n",
      " Батч  200 из  324. Затраченное время: 00:08:20. Ошибка: 0.6276447176933289.\n",
      " Батч  210 из  324. Затраченное время: 00:08:45. Ошибка: 0.6402776837348938.\n",
      " Батч  220 из  324. Затраченное время: 00:09:10. Ошибка: 0.31140249967575073.\n",
      " Батч  230 из  324. Затраченное время: 00:09:34. Ошибка: 0.7339197397232056.\n",
      " Батч  240 из  324. Затраченное время: 00:09:59. Ошибка: 0.7770240306854248.\n",
      " Батч  250 из  324. Затраченное время: 00:10:24. Ошибка: 0.5650066137313843.\n",
      " Батч  260 из  324. Затраченное время: 00:10:49. Ошибка: 0.5336060523986816.\n",
      " Батч  270 из  324. Затраченное время: 00:11:13. Ошибка: 0.8697284460067749.\n",
      " Батч  280 из  324. Затраченное время: 00:11:38. Ошибка: 0.42191675305366516.\n",
      " Батч  290 из  324. Затраченное время: 00:12:02. Ошибка: 0.6327349543571472.\n",
      " Батч  300 из  324. Затраченное время: 00:12:27. Ошибка: 0.8080720901489258.\n",
      " Батч  310 из  324. Затраченное время: 00:12:51. Ошибка: 0.625245988368988.\n",
      " Батч  320 из  324. Затраченное время: 00:13:16. Ошибка: 1.340185284614563.\n",
      "\n",
      " Средний loss: 0.69\n",
      " Обучение эпохи прошло за: 00:13:23\n",
      "\n",
      " Validation...\n",
      "  Accuracy: 0.70\n",
      "  Валидация прошла за: 00:00:16\n",
      "\n",
      "Эпоха 2 из 4 \n",
      " Батч   10 из  324. Затраченное время: 00:00:27. Ошибка: 0.7657690644264221.\n",
      " Батч   20 из  324. Затраченное время: 00:00:52. Ошибка: 0.6096266508102417.\n",
      " Батч   30 из  324. Затраченное время: 00:01:17. Ошибка: 0.38568904995918274.\n",
      " Батч   40 из  324. Затраченное время: 00:01:42. Ошибка: 0.4752410650253296.\n",
      " Батч   50 из  324. Затраченное время: 00:02:07. Ошибка: 0.7426087856292725.\n",
      " Батч   60 из  324. Затраченное время: 00:02:31. Ошибка: 0.5468617677688599.\n",
      " Батч   70 из  324. Затраченное время: 00:02:56. Ошибка: 1.086529016494751.\n",
      " Батч   80 из  324. Затраченное время: 00:03:20. Ошибка: 0.5518712997436523.\n",
      " Батч   90 из  324. Затраченное время: 00:03:45. Ошибка: 0.8128534555435181.\n",
      " Батч  100 из  324. Затраченное время: 00:04:10. Ошибка: 0.5873131155967712.\n",
      " Батч  110 из  324. Затраченное время: 00:04:35. Ошибка: 0.6305773258209229.\n",
      " Батч  120 из  324. Затраченное время: 00:04:59. Ошибка: 0.5273537039756775.\n",
      " Батч  130 из  324. Затраченное время: 00:05:24. Ошибка: 0.6302574872970581.\n",
      " Батч  140 из  324. Затраченное время: 00:05:48. Ошибка: 0.5748608112335205.\n",
      " Батч  150 из  324. Затраченное время: 00:06:13. Ошибка: 0.6039876341819763.\n",
      " Батч  160 из  324. Затраченное время: 00:06:37. Ошибка: 0.602645754814148.\n",
      " Батч  170 из  324. Затраченное время: 00:07:02. Ошибка: 0.5221444368362427.\n",
      " Батч  180 из  324. Затраченное время: 00:07:26. Ошибка: 0.3788638710975647.\n",
      " Батч  190 из  324. Затраченное время: 00:07:51. Ошибка: 0.8721861243247986.\n",
      " Батч  200 из  324. Затраченное время: 00:08:16. Ошибка: 0.8048152923583984.\n",
      " Батч  210 из  324. Затраченное время: 00:08:40. Ошибка: 0.7383074760437012.\n",
      " Батч  220 из  324. Затраченное время: 00:09:05. Ошибка: 0.762800395488739.\n",
      " Батч  230 из  324. Затраченное время: 00:09:30. Ошибка: 0.34436601400375366.\n",
      " Батч  240 из  324. Затраченное время: 00:09:54. Ошибка: 0.9107928276062012.\n",
      " Батч  250 из  324. Затраченное время: 00:10:19. Ошибка: 0.5532724261283875.\n",
      " Батч  260 из  324. Затраченное время: 00:10:44. Ошибка: 0.8600908517837524.\n",
      " Батч  270 из  324. Затраченное время: 00:11:09. Ошибка: 0.6899023652076721.\n",
      " Батч  280 из  324. Затраченное время: 00:11:34. Ошибка: 0.48551538586616516.\n",
      " Батч  290 из  324. Затраченное время: 00:11:58. Ошибка: 0.6077355146408081.\n",
      " Батч  300 из  324. Затраченное время: 00:12:23. Ошибка: 0.9498401880264282.\n",
      " Батч  310 из  324. Затраченное время: 00:12:48. Ошибка: 0.5782105922698975.\n",
      " Батч  320 из  324. Затраченное время: 00:13:12. Ошибка: 0.47499775886535645.\n",
      "\n",
      " Средний loss: 0.65\n",
      " Обучение эпохи прошло за: 00:13:19\n",
      "\n",
      " Validation...\n",
      "  Accuracy: 0.70\n",
      "  Валидация прошла за: 00:00:15\n",
      "\n",
      "Эпоха 3 из 4 \n",
      " Батч   10 из  324. Затраченное время: 00:00:27. Ошибка: 0.5501180291175842.\n",
      " Батч   20 из  324. Затраченное время: 00:00:51. Ошибка: 0.5360552668571472.\n",
      " Батч   30 из  324. Затраченное время: 00:01:15. Ошибка: 0.2358666956424713.\n",
      " Батч   40 из  324. Затраченное время: 00:01:40. Ошибка: 0.5147519111633301.\n",
      " Батч   50 из  324. Затраченное время: 00:02:04. Ошибка: 1.253104567527771.\n",
      " Батч   60 из  324. Затраченное время: 00:02:28. Ошибка: 0.49266499280929565.\n",
      " Батч   70 из  324. Затраченное время: 00:02:53. Ошибка: 0.629077672958374.\n",
      " Батч   80 из  324. Затраченное время: 00:03:17. Ошибка: 0.8018711805343628.\n",
      " Батч   90 из  324. Затраченное время: 00:03:42. Ошибка: 0.5529108643531799.\n",
      " Батч  100 из  324. Затраченное время: 00:04:06. Ошибка: 0.6183215975761414.\n",
      " Батч  110 из  324. Затраченное время: 00:04:30. Ошибка: 0.7442324757575989.\n",
      " Батч  120 из  324. Затраченное время: 00:04:55. Ошибка: 1.2033571004867554.\n",
      " Батч  130 из  324. Затраченное время: 00:05:19. Ошибка: 0.5580628514289856.\n",
      " Батч  140 из  324. Затраченное время: 00:05:44. Ошибка: 0.7751632928848267.\n",
      " Батч  150 из  324. Затраченное время: 00:06:08. Ошибка: 0.8520776033401489.\n",
      " Батч  160 из  324. Затраченное время: 00:06:32. Ошибка: 0.7291372418403625.\n",
      " Батч  170 из  324. Затраченное время: 00:06:57. Ошибка: 0.7543044090270996.\n",
      " Батч  180 из  324. Затраченное время: 00:07:21. Ошибка: 0.5766345858573914.\n",
      " Батч  190 из  324. Затраченное время: 00:07:45. Ошибка: 0.618707537651062.\n",
      " Батч  200 из  324. Затраченное время: 00:08:10. Ошибка: 0.5249047875404358.\n",
      " Батч  210 из  324. Затраченное время: 00:08:34. Ошибка: 0.8570268154144287.\n",
      " Батч  220 из  324. Затраченное время: 00:08:59. Ошибка: 0.5766189694404602.\n",
      " Батч  230 из  324. Затраченное время: 00:09:23. Ошибка: 0.5704665184020996.\n",
      " Батч  240 из  324. Затраченное время: 00:09:47. Ошибка: 0.2676236629486084.\n",
      " Батч  250 из  324. Затраченное время: 00:10:11. Ошибка: 0.5125942826271057.\n",
      " Батч  260 из  324. Затраченное время: 00:10:36. Ошибка: 0.5850394368171692.\n",
      " Батч  270 из  324. Затраченное время: 00:11:00. Ошибка: 0.5086669325828552.\n",
      " Батч  280 из  324. Затраченное время: 00:11:24. Ошибка: 1.1765652894973755.\n",
      " Батч  290 из  324. Затраченное время: 00:11:48. Ошибка: 0.9300839900970459.\n",
      " Батч  300 из  324. Затраченное время: 00:12:13. Ошибка: 0.6051758527755737.\n",
      " Батч  310 из  324. Затраченное время: 00:12:37. Ошибка: 0.6100082993507385.\n",
      " Батч  320 из  324. Затраченное время: 00:13:02. Ошибка: 0.6393169164657593.\n",
      "\n",
      " Средний loss: 0.64\n",
      " Обучение эпохи прошло за: 00:13:09\n",
      "\n",
      " Validation...\n",
      "  Accuracy: 0.70\n",
      "  Валидация прошла за: 00:00:15\n",
      "\n",
      "Эпоха 4 из 4 \n",
      " Батч   10 из  324. Затраченное время: 00:00:26. Ошибка: 0.5538405179977417.\n",
      " Батч   20 из  324. Затраченное время: 00:00:51. Ошибка: 0.7073623538017273.\n",
      " Батч   30 из  324. Затраченное время: 00:01:15. Ошибка: 0.6360711455345154.\n",
      " Батч   40 из  324. Затраченное время: 00:01:39. Ошибка: 0.6232317090034485.\n",
      " Батч   50 из  324. Затраченное время: 00:02:03. Ошибка: 0.8197153806686401.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Батч   60 из  324. Затраченное время: 00:02:27. Ошибка: 0.5810228586196899.\n",
      " Батч   70 из  324. Затраченное время: 00:02:51. Ошибка: 0.31337493658065796.\n",
      " Батч   80 из  324. Затраченное время: 00:03:15. Ошибка: 0.5163186192512512.\n",
      " Батч   90 из  324. Затраченное время: 00:03:39. Ошибка: 0.5010719299316406.\n",
      " Батч  100 из  324. Затраченное время: 00:04:03. Ошибка: 0.22985947132110596.\n",
      " Батч  110 из  324. Затраченное время: 00:04:27. Ошибка: 0.5804225206375122.\n",
      " Батч  120 из  324. Затраченное время: 00:04:51. Ошибка: 0.838504433631897.\n",
      " Батч  130 из  324. Затраченное время: 00:05:14. Ошибка: 0.5485562086105347.\n",
      " Батч  140 из  324. Затраченное время: 00:05:39. Ошибка: 0.5896535515785217.\n",
      " Батч  150 из  324. Затраченное время: 00:06:02. Ошибка: 0.8476449251174927.\n",
      " Батч  160 из  324. Затраченное время: 00:06:26. Ошибка: 0.43970417976379395.\n",
      " Батч  170 из  324. Затраченное время: 00:06:50. Ошибка: 0.41628867387771606.\n",
      " Батч  180 из  324. Затраченное время: 00:07:14. Ошибка: 0.46648722887039185.\n",
      " Батч  190 из  324. Затраченное время: 00:07:38. Ошибка: 0.7941492795944214.\n",
      " Батч  200 из  324. Затраченное время: 00:08:02. Ошибка: 1.0742343664169312.\n",
      " Батч  210 из  324. Затраченное время: 00:08:26. Ошибка: 0.19290603697299957.\n",
      " Батч  220 из  324. Затраченное время: 00:08:50. Ошибка: 0.6597568392753601.\n",
      " Батч  230 из  324. Затраченное время: 00:09:14. Ошибка: 0.3931540846824646.\n",
      " Батч  240 из  324. Затраченное время: 00:09:38. Ошибка: 0.7024127244949341.\n",
      " Батч  250 из  324. Затраченное время: 00:10:02. Ошибка: 1.1553685665130615.\n",
      " Батч  260 из  324. Затраченное время: 00:10:26. Ошибка: 0.44408124685287476.\n",
      " Батч  270 из  324. Затраченное время: 00:10:49. Ошибка: 0.35242149233818054.\n",
      " Батч  280 из  324. Затраченное время: 00:11:13. Ошибка: 0.8492833971977234.\n",
      " Батч  290 из  324. Затраченное время: 00:11:37. Ошибка: 0.9114657640457153.\n",
      " Батч  300 из  324. Затраченное время: 00:12:01. Ошибка: 0.4980694353580475.\n",
      " Батч  310 из  324. Затраченное время: 00:12:25. Ошибка: 0.8805209398269653.\n",
      " Батч  320 из  324. Затраченное время: 00:12:49. Ошибка: 0.30898311734199524.\n",
      "\n",
      " Средний loss: 0.61\n",
      " Обучение эпохи прошло за: 00:12:56\n",
      "\n",
      " Validation...\n",
      "  Accuracy: 0.68\n",
      "  Валидация прошла за: 00:00:15\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "Error no file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory ./model_save_toxic/.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4f5abe75c544>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[1;31m# Загрузим предобученную модель\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[0mmodel_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./model_save_toxic/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 303\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertForSequenceClassification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    304\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3761\u001b[0m                     )\n\u001b[0;32m   3762\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3763\u001b[1;33m                     raise EnvironmentError(\n\u001b[0m\u001b[0;32m   3764\u001b[0m                         \u001b[1;34mf\"Error no file named {_add_variant(WEIGHTS_NAME, variant)}, {_add_variant(SAFE_WEIGHTS_NAME, variant)},\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3765\u001b[0m                         \u001b[1;34mf\" {TF2_WEIGHTS_NAME}, {TF_WEIGHTS_NAME + '.index'} or {FLAX_WEIGHTS_NAME} found in directory\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Error no file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory ./model_save_toxic/."
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Dec  9 14:27:26 2024\n",
    "\n",
    "@author: Vanya\n",
    "\"\"\"\n",
    "# pip install tensorflow\n",
    "# pip install tensorflow-gpu\n",
    "# pip install transformers\n",
    "# pip install kernel\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Проверяем доступна ли GPU и задаем вычислительное устройство\n",
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('Available GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU')\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "# В работе используется набор Russian Language Toxic Comments Dataset https://www.kaggle.com/blackmoon/russian-language-toxic-comments\n",
    "# комментариев с сайтов Двач и Пикабу. \n",
    "# он опубликован  в 2019 году и содержит 14 412 комментариев\n",
    "# 4 826 из них помечены как токсичные, а 9 586 — как нетоксичные\n",
    "\n",
    "# Загрузка данных реализована на основе pandas dataframe\n",
    "df = pd.read_csv(\"data/labeled_rutoxic.csv\", delimiter=',', header=0, names=['sentence', 'label'])\n",
    "\n",
    "# Выбираем 10% случайных значений\n",
    "df = df.sample(frac=0.1, random_state=42)\n",
    "\n",
    "print('В наборе предложений: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "# Пример\n",
    "df.sample(10)\n",
    "\n",
    "# Нас интересуют метки классов и сами предложения, на них мы будем обучать нашу сеть\n",
    "sentences = df.sentence.values\n",
    "labels = df.label.values\n",
    "\n",
    "# Следующий этап - токенизация - разбиение предложений на слова\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Используем BERT tokenizer, но созданный на основе словаря\n",
    "tokenizer = BertTokenizer('data/vocab_rutoxic.txt', do_lower_case=True, do_basic_tokenize=True, never_split=None)\n",
    "\n",
    "##### размер нового словаря\n",
    "tokenizer.vocab_size\n",
    "\n",
    "# максимальный размер предложения существенно вырос\n",
    "sl = [len(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sen))) for sen in sentences]\n",
    "print('Максимальная длина предложения: ', max([len(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sen))) for sen in sentences]))\n",
    "\n",
    "# посмотрим сколько предложений имеет длину более 64 символа\n",
    "value_c = pd.Series(sl).value_counts()\n",
    "print('Предложений длиннее 64 токена: ', sum(value_c[64:]))\n",
    "\n",
    "# довольно много, но придется ими пожертвовать\n",
    "# будем их обрезать\n",
    "\n",
    "input_ids = np.zeros((len(sentences),64))\n",
    "\n",
    "# Каждое предложение энкодится по отдельности\n",
    "for s,i in zip(sentences,range(len(sentences))):\n",
    "    enc_s = tokenizer.encode(s,                      \n",
    "                        add_special_tokens = True, # У казываем, что нам нужно добавить служебные токены\n",
    "                        padding = 'max_length',  # дополнение до макс.длины\n",
    "                        max_length = 64,         # максимальная длина предложений\n",
    "                        truncation = True        # все что длиннее max_length будет обрезаться\n",
    "                   )\n",
    "    # Формируем список id токенов\n",
    "    input_ids[i,]=enc_s\n",
    "\n",
    "\n",
    "# Создаем attention mask для виртуальных токенов\n",
    "attention_masks = []\n",
    "\n",
    "for s in input_ids:\n",
    "    #   Если ID = 0, это виртуальный токен и маска для него 0.\n",
    "    #   Если ID > 0, это реальный токен и маска для него 1.\n",
    "    att_mask = [int(id_ > 0) for id_ in s]\n",
    "    attention_masks.append(att_mask)\n",
    "\n",
    "\n",
    "# Формируем тестовый и валидационный набор\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# разбиваем данные, метки классов\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, test_size=0.1)\n",
    "# и маску\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels, test_size=0.1)\n",
    "\n",
    "# все конвертируем в тензоры\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "\n",
    "# теперь можно создавать Dataset и DataLoader\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# размер батча придется уменьшить (если на GPU), т.к. за счет\n",
    "# увеличившегося словаря выросла и модель \n",
    "batch_size = 4\n",
    "\n",
    "# Пакуем в тренировочный предложения (ID), маску и метки классов\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# и в валидационный\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n",
    "\n",
    "# теперь можно переходить к заданию модели\n",
    "\n",
    "from transformers import BertForSequenceClassification, AdamW, PretrainedConfig, BertConfig\n",
    "\n",
    "# Загрузка теперь делается через конфигурационный файл, в котором изменен размер словаря\n",
    "configuration = BertConfig.from_pretrained('data/config_rutoxic.json')\n",
    "model = BertForSequenceClassification(configuration)\n",
    "\n",
    "# Отправляем модель на GPU\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "# Задаем оптимизатор\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # скорость обучения\n",
    "                  eps = 1e-8 # специфический параметр, повышающий стабильность обучения\n",
    "                )\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Количество эпох обучения\n",
    "epochs = 4\n",
    "\n",
    "# Шагов обучения = number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# scheduler - планировщик изменяющий скорость обучения\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)\n",
    "\n",
    "# функция вычисления точности обучения\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "# Задаем seed\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Тут храним наши лоссы\n",
    "loss_values = []\n",
    "\n",
    "# Цикл обучения будет состоять из обучения и валидации\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    ################ Часть обучения #####################\n",
    "    \n",
    "    print(\"\")\n",
    "    print('Эпоха {:} из {:} '.format(epoch_i + 1, epochs))\n",
    "    \n",
    "    t0 = time.time()\n",
    "\n",
    "    # потери за эпоху\n",
    "    total_loss = 0\n",
    "    \n",
    "    # переключаем в режим обучения\n",
    "    model.train()\n",
    "\n",
    "    # пробегаем по батчам\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "       \n",
    "        # Достаем из батча данные: предложения, маску и метки\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # обнуляем градиенты\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # прямой проход\n",
    "        outputs = model(b_input_ids.to(torch.long), \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask.to(torch.long), \n",
    "                    labels=b_labels.to(torch.long))\n",
    "       \n",
    "               # потери\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # обратный проход\n",
    "        loss.backward()\n",
    "\n",
    "        # обрезаем градиенты до 1.0, чтобы предотвратить \"взрыв градиентов\"\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # обновляем параметры модели\n",
    "        optimizer.step()\n",
    "\n",
    "        # изменяем скорость обучения\n",
    "        scheduler.step()\n",
    "        \n",
    "         # диагностическую информацию выводим каждые 10 батчей\n",
    "        if step % 10 == 0 and not step == 0:\n",
    "            time_elapsed = time.strftime(\"%H:%M:%S\", time.gmtime(time.time() - t0))\n",
    "            print(' Батч {:>4,} из {:>4,}. Затраченное время: {:}. Ошибка: {:}.'.format(step, len(train_dataloader), time_elapsed, loss))\n",
    "\n",
    "\n",
    "    # средний loss \n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "    # сохраним для графика\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\" Средний loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\" Обучение эпохи прошло за: {:}\".format(time.strftime(\"%H:%M:%S\", time.gmtime(time.time() - t0))))\n",
    "\n",
    "    ################ Часть валидации #####################\n",
    "    # Позволяет понять правильно ли мы учимся и учимся ли вообще\n",
    "\n",
    "    print(\"\\n Validation...\")\n",
    "    t0 = time.time()\n",
    "\n",
    "    # модель в  evaluation режим\n",
    "    model.eval()\n",
    "\n",
    "    # диагностические переменные\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # пробегаем валидационный набор\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # берем нужные данные из батча\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        with torch.no_grad():        \n",
    "            # прямой проход\n",
    "            outputs = model(b_input_ids.to(torch.long), \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask.to(torch.long), \n",
    "                    labels=b_labels.to(torch.long))\n",
    "        \n",
    "        # \"logits\" хранят вероятности классов похоже на softmax\n",
    "        logits = outputs.logits\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # считаем точность модели на валидации\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        # суммарная точность\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        # сколько батчей прошло\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    # результат валидации\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Валидация прошла за: {:}\".format(time.strftime(\"%H:%M:%S\", time.gmtime(time.time() - t0))))\n",
    "\n",
    "\n",
    "\n",
    "# Можно построить график обучения \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_values, 'b-o')\n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae13c016",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Error no file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory model_save_toxic.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-9af78f638810>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Загрузим предобученную модель\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'model_save_toxic'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertForSequenceClassification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3761\u001b[0m                     )\n\u001b[0;32m   3762\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3763\u001b[1;33m                     raise EnvironmentError(\n\u001b[0m\u001b[0;32m   3764\u001b[0m                         \u001b[1;34mf\"Error no file named {_add_variant(WEIGHTS_NAME, variant)}, {_add_variant(SAFE_WEIGHTS_NAME, variant)},\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3765\u001b[0m                         \u001b[1;34mf\" {TF2_WEIGHTS_NAME}, {TF_WEIGHTS_NAME + '.index'} or {FLAX_WEIGHTS_NAME} found in directory\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Error no file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory model_save_toxic."
     ]
    }
   ],
   "source": [
    "# # Загрузим предобученную модель\n",
    "# model_dir = 'model_save_toxic'\n",
    "# model = BertForSequenceClassification.from_pretrained(model_dir)\n",
    "# tokenizer = BertTokenizer.from_pretrained(model_dir)\n",
    "\n",
    "# configuration = BertConfig.from_pretrained('data/config_rutoxic.json')\n",
    "# model = BertForSequenceClassification(configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "575af2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "\n",
    "# Проверим как оно работает\n",
    "sentence = 'чурки'\n",
    "# sentence = 'Ну, посмотрел я комментарии к твоим постам, процент говнокомментов ниже средней отметки.'\n",
    "enc_s = tokenizer.encode(sentence,                      \n",
    "                        add_special_tokens = True, # У казываем, что нам нужно добавить служебные токены\n",
    "                        padding = 'max_length',  # дополнение до макс.длины\n",
    "                        max_length = 64,         # максимальная длина предложений\n",
    "                        truncation = True        # все что длиннее max_length будет обрезаться\n",
    "                   )\n",
    "\n",
    "# Формируем список id токенов\n",
    "input_ids = np.array(enc_s)\n",
    "\n",
    "# Создаем attention mask для виртуальных токенов\n",
    "attention_mask = [int(id_ > 0) for id_ in input_ids]\n",
    "\n",
    "model.eval()\n",
    "batch = tuple(t.to(device) for t in torch.Tensor([input_ids, attention_mask]))\n",
    "b_input_ids, b_input_mask = batch\n",
    "with torch.no_grad():\n",
    "    outputs = model( b_input_ids.unsqueeze(0).to(torch.long), token_type_ids=None, attention_mask=b_input_mask.unsqueeze(0))\n",
    "    \n",
    "logits = outputs.logits\n",
    "logits = logits.detach().cpu().numpy()\n",
    "predicted_label = np.argmax(logits, axis=1).flatten()\n",
    "print(predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fa26bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
